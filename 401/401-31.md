## Beginner's Guide to Docker
Pro: Don't have to use virtual environments -> instead, reproduce a production environment locally  
Con: complexity  

Docker is a way to implement Linux containter (containerization), which is a type of virtualization. 

### Containers vs Virtual Environments
Virual enviroments: used to isolate Python packages locally. They rely on global, system-level installation of Python on the computer itself, no actually within the virtual environment. We can't run production database so it's limiting. 

### Install Docker
1. Download desktop app and create a free account
2. Check version - should be at least version 19
3. (On Linux) Download Docker Compose (already given to Windows/Mac)
4. Run POL command `docker run hello-world`, which downloads an official image and runs container
5. Run inspect command `docker info`

Other commands:  
`docker image ls`: inspect current image    
`docker container ls -la`: inspect container   
(`ls -la` for stopped containers, `ls` for running containers)   

### Images and Containers
image: snapshot in time of what a project contains  
- custom images are created using a `Dockerfile` 
- `docker-compose.yml` files run containers

Example analogy:
- dockerfile is the recipe for a cake
- image is a snapshot of the recipe at a given time
- docker-compose.yml says how to make the cake (instructions)
- container is the actual cake

### Images
Create an image and container:  

Create a local directory:  
  $ cd ~/Desktop  
  $ mkdir docker_project   
  $ cd docker_project  
  $ mkdir python3.7  
  $ cd python3.7  

Define the image with a dockerfile (list of all requirements needed to build the image):  
  $ touch Dockerfile  
  - Within text editor - Dockerfile add the following code:  
  - `FROM python:3.7-alpine`  
  - first instruction must be the FROM command which lets us import a base image to use for our image    

### Image Builds
Build/create the image:  
$ docker image build . (don't forget the period!)  
> output: Successfully built + hash id  
 
Check if Docker image exists:  
$ docker image ls  

### Image Layers
Each image layer is immutable to ensure consistency when two devs build the same image. Docker caches the layering steps in a Dockerfile to speed up subsequent builds. When a change is made to a step, all proceeding steps are executed from scratch (order matters!). Put code that won't change at the top and code that might change at the end. 

### Containers
Example from scratch:  
directory: djangoapp  

Django  
1. install django and enter virtual env shell  
  $ mkdir djangoapp && cd djangoapp  
  $ pipenv install django==3.0  
  $ pipenv shell  
  (creates a pipfile and pipfile.lock)  
2. create an example_project   
  (djangoapp) $ django-admin startproject example_project .   
3. runserver  
  (djangoapp) $ python manage.py runserver  
4. exit virtual environment   
5. confirm what exisits in our local directory  
  $ ls  

Docker
1. create a dockerfile for our image (which replaces of local dev environment) and add a yml file for the container instructions  
  $ touch Dockerfile  
  $ touch docker-compose.yml  
2. update the dockerfile (run, copy, add, create new layer)  
  ```
  # Dockerfile

  # Python version
  FROM python:3.7-alpine

  # Set environment variables
  # removes .pyc files from our container for optimization
  ENV PYTHONDONTWRITEBYTECODE 1
  # buffers our output so it looks normal within Docker
  ENV PYTHONUNBUFFERED 1

  # Set work directory
  WORKDIR /code

  # Install dependencies
  COPY Pipfile Pipfile.lock /code/
  RUN pip install pipenv && pipenv install --system

  # Copy project - any changes locally will be copied over
  COPY . /code/
  ```


3. update docker-compose.yml  
  ```
  # docker-compose.yml
  version: '3.7'

  services:
    web:
      build: .
      command: python /code/manage.py runserver 0.0.0.0:8000
      volumes:
        - .:/code
      ports:
        - 8000:8000
  ```
  
4. build image and run the container in one step  
  $ docker-compose up --build  


## Django Rest Frameword
$ pipenv install djangorestframework~=3.11.0  
> add to `INSTALLED_APPS` in settings.py  
> `'rest_framework',`  

Organize files by creating a dedicated `api` app.   
$ python manage.py startapp api  
> add to `INSTALLED_APPS` in settings.py  
> `'api',`  
> no need to migrate since it does not have its own database models  

URL configs:
```
# config/urls.py
from django.contrib import admin
from django.urls import path, include

urlpatterns = [
    path('admin/', admin.site.urls),
    path('api/', include('api.urls')), # new
    path('', include('books.urls')),
]
```

Create a urls.py: 
$ touch api/urls.py

```
# api/urls.py
from django.urls import path
from .views import BookAPIView

urlpatterns = [
    path('', BookAPIView.as_view()),
]
```

Views:
```
# api/views.py
from rest_framework import generics

from books.models import Book
from .serializers import BookSerializer


class BookAPIView(generics.ListAPIView):
    queryset = Book.objects.all()
    serializer_class = BookSerializer
```

Serializers:  
Translates data into a format that is easily consumable. Convert Django models to JSON.   

$ touch api/serializers.py  

```
# api/serializers.py
from rest_framework import serializers

from books.models import Book


class BookSerializer(serializers.ModelSerializer):
    class Meta:
        model = Book
        fields = ('title', 'subtitle', 'author', 'isbn')
```

cURL:  
API endpoints.   

$ python manage.py runserver  

In a second CLI window:  
$ curl http://127.0.0.1:8000/api/  