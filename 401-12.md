# Panda Panda Panda Panda
```
import numpy as np
import pandas as pd
```
## Object Creation
`Series` - pass a list of values, which lets pandas create a default integer index  
`DataFrame` - pass a NumPy array, with a datetime index and labeled columns. Pass a dict of objects that can be converted to series-like.  

## Viewing Data
View the top and bottom rows of the frame: `df.head()` & `df.tail(3)`  
Display the index, columns: `df.index` & `df.columns`  
`DataFrame.to_numpy()`: NumPy representation of the underlying data (fyi - expensive if columns have different data types)  
> NumPy arrays have one dtype for the entire array, while pandas DataFrames have one dtype per column. Pandas will find the NumPy dtype that can hold all of the dtypes in the DataFrame. This may end up being object, which requires casting every value to a Python object. Does not include the index or column labels in the output.  

`describe()`: shows a quick statistic summary of your data  
`df.T`: transposes the data  
`df.sort_index(axis=1, ascending=False)`: sort by axis  
`df.sort_values(by="B")`: sorts by values  

## Selection
`df.A`: selects a single column which yields a Series  
`[:]`: slices the row with given indexes  
`df.loc[dates[0]]`: get cross section using a label  
`df.loc[:, ["A", "B"]]`: select multi-axis by label  
`df.loc["20130102":"20130104", ["A", "B"]]`: label slicing with both endpoints included  
`df.loc["20130102", ["A", "B"]]`: reduction in the dimensions of the returned object  
`df.loc[dates[0], "A"]`: get scalar value  
`df.at[dates[0], "A"]`: fast access to scalar value  
`df.iloc[3]`: select with the position of the passed integers  
`df.iloc[3:5, 0:2]`: select by integer slices (similar to numpy)  
`df.iloc[[1, 2, 4], [0, 2]]`: select by lists of integer   position locations (similar to numpy)  
`df.iloc[1:3, :]`: slice row explicitly  
`df.iloc[:, 1:3]`: slic column explicitly  
`df.iloc[1, 1]`: get value explicitly  
`df.iat[1, 1]`: fast access to scalar  
`df[df["A"] > 0]`: boolean indexing - singly column's value to select data  
`df[df > 0]`: selecting values from DataFrame where boolean condition is met  
`df2[df2["E"].isin(["two", "four"])]`: `isin()` method for filtering  
`df["F"] = s1`: setting new column aligns the data by indexes  
`df.at[dates[0], "A"] = 0`: setting values by label  
`df.iat[0, 1] = 0`: setting values by positions  
`df.loc[:, "D"] = np.array([5] * len(df))`: setting by assigning with a NumPy array  

## Missing Data
Primarily uses `np.nan` to represent missing data (by default). Reindexing allows changing/adding/deleting the index of a specified axis and returns a copy of the data:
```
df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + ["E"])
df1.loc[dates[0] : dates[1], "E"] = 1
```
`df1.dropna(how="any")`: drop any rows that have missing data  
`df1.fillna(value=5)`: fill missing data  
`pd.isna(df1)`: get boolean mask where values are `nan`  

## Operations
`df.mean()`: descriptive statistic  
`df.mean(1)`: descriptive statistic on other axis  
`df.sub(s, axis="index")`: different dimensionality and needs alignment along the specified dimension  
`df.apply(np.cumsum)`, `df.apply(lambda x: x.max() - x.min())`: apply functions to the data  
`s.value_counts()`: histogramming  
`s.str.lower()`: str generally uses regex by default  

## Merge
`pd.concat(pieces)`: concatenate pandas objects together  
`pd.merge(left, right, on="key")`: SQL style merge  

## Grouping
- Splitting the data into groups based on some criteria   
- Applying a function to each group independently   
- Combining the results into a data structure    

`df.groupby("A").sum()`: grouping then apply `sum()` function to resulting groups  
`df.groupby(["A", "B"]).sum()`: grouping by multiple columns to form a hierarchical index (and then apply sum function)  

## Reshaping
`stacked = df2.stack()`: compresses a level in the DataFrame's columns  
`stacked.unstack()`: unstacks the last level  
`pd.pivot_table(df, values="D", index=["A", "B"], columns=["C"])`: create a pivot table  

## Time Series
```
In [104]: rng = pd.date_range("1/1/2012", periods=100, freq="S")
In [105]: ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)
In [106]: ts.resample("5Min").sum()
```
`ts_utc = ts.tz_localize("UTC")`: time zone representation  
`ts_utc.tz_convert("US/Eastern")`: convert time zone  
`ps = ts.to_period()`, `ps.to_timestamp()`: convert between time span   

## Categoricals
`df["grade"] = df["raw_grade"].astype("category")`: convert raw grades to categorical data type  
`df["grade"].cat.categories = ["very good", "good", "very bad"]`: rename catgories  
```
df["grade"] = df["grade"].cat.set_categories(
     ["very bad", "bad", "medium", "good", "very good"]
)
```
^reorder categories and simultaneously add missing categories  
`df.sort_values(by="grade")`: sorting per order in the categories (not lexical order)  
`df.groupby("grade").size()`: grouping by categorical column shows empty categories  

## Plotting
```
In [131]: import matplotlib.pyplot as plt
In [132]: plt.close("all")
----
In [133]: ts = pd.Series(np.random.randn(1000), index=pd.date_range("1/1/2000", periods=1000))
In [134]: ts = ts.cumsum()
In [135]: ts.plot()
Out[135]: <AxesSubplot:>
```
`df.plot()`: plot all of the columns with labels

## Getting data in/out
Writing to a csv file:
```
In [141]: df.to_csv("foo.csv")
```
Reading from a csv file:
```
In [142]: pd.read_csv("foo.csv")
```
Writing to a HDF5 Store:
```
In [143]: df.to_hdf("foo.h5", "df")
```
Reading from a HDF5 Store:
```
In [144]: pd.read_hdf("foo.h5", "df")
```
Writing to an excel file:
```
In [145]: df.to_excel("foo.xlsx", sheet_name="Sheet1")
```
Reading from an excel file:
```
In [146]: pd.read_excel("foo.xlsx", "Sheet1", index_col=None, na_values=["NA"])
```


